behaviors:
  CarBehavior:  #  Give your behavior a name (used in the Unity editor)
    trainer_type: ppo  #  Specify the PPO trainer
    hyperparameters:
      batch_size: 128 # Was 64
      buffer_size: 2048  # Was 1024, must be a multiple of batch_size
      learning_rate: 3.0e-4
      beta: 5.0e-3
      epsilon: 0.2
      lambd: 0.95
      num_epoch: 3
      learning_rate_schedule: linear
    network_settings:
      normalize: false  #  You're already normalizing in CollectObservations
      hidden_units: 128  #  Number of neurons in each hidden layer
      num_layers: 2  #  Number of hidden layers
    reward_signals:
      extrinsic:  #  Rewards from the environment (your AddReward calls)
        gamma: 0.99
        strength: 1.0
    max_steps: 5.0e5  #  Total training steps (500,000)
    time_horizon: 64 #was 64
    summary_freq: 100